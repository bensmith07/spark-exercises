{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6171db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b523ea6a",
   "metadata": {},
   "source": [
    "#### 1. Create a spark data frame that contains your favorite programming languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1cd0812",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.createDataFrame(pd.DataFrame({'language': ['python', \n",
    "                                                       'sql', \n",
    "                                                       'javascript', \n",
    "                                                       'C++', \n",
    "                                                       'java']}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51152add",
   "metadata": {},
   "source": [
    "#### view the schma of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "752f0c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(language,StringType,true)))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b559b403",
   "metadata": {},
   "source": [
    "#### output the shape of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b870bd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1461, 8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.count(), len(sdf.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcf3bac",
   "metadata": {},
   "source": [
    "#### Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6342c8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|  language|\n",
      "+----------+\n",
      "|    python|\n",
      "|       sql|\n",
      "|javascript|\n",
      "|       C++|\n",
      "|      java|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4326cd",
   "metadata": {},
   "source": [
    "#### 2. Load the mpg dataset as a spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4017726f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydataset import data\n",
    "sdf = spark.createDataFrame(data('mpg'))\n",
    "sdf.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6a6110",
   "metadata": {},
   "source": [
    "#### 2a. Create 1 column of output that contains a message like the one below\n",
    "> The 1999 audi a4 has a 4 cylinder engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f866d316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------+\n",
      "|concat(The , year,  , model,  has a , cyl,  cylinder engine.)|\n",
      "+-------------------------------------------------------------+\n",
      "|The 1999 a4 has a 4 cylinder engine.                         |\n",
      "|The 1999 a4 has a 4 cylinder engine.                         |\n",
      "|The 2008 a4 has a 4 cylinder engine.                         |\n",
      "|The 2008 a4 has a 4 cylinder engine.                         |\n",
      "|The 1999 a4 has a 6 cylinder engine.                         |\n",
      "|The 1999 a4 has a 6 cylinder engine.                         |\n",
      "|The 2008 a4 has a 6 cylinder engine.                         |\n",
      "|The 1999 a4 quattro has a 4 cylinder engine.                 |\n",
      "|The 1999 a4 quattro has a 4 cylinder engine.                 |\n",
      "|The 2008 a4 quattro has a 4 cylinder engine.                 |\n",
      "+-------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.message = F.concat(F.lit('The '), \n",
    "                       sdf.year, \n",
    "                       F.lit(' '), \n",
    "                       sdf.model, \n",
    "                       F.lit(' has a '),\n",
    "                       sdf.cyl, \n",
    "                       F.lit(' cylinder engine.'))\n",
    "sdf.select(sdf.message).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5f0918",
   "metadata": {},
   "source": [
    "#### 2b. Transform the trans column so that it only contains either manual or auto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b9e29ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+\n",
      "|regexp_extract(trans, (\\w+), 1)|\n",
      "+-------------------------------+\n",
      "|                           auto|\n",
      "|                         manual|\n",
      "|                         manual|\n",
      "|                           auto|\n",
      "|                           auto|\n",
      "|                         manual|\n",
      "|                           auto|\n",
      "|                         manual|\n",
      "|                           auto|\n",
      "|                         manual|\n",
      "|                           auto|\n",
      "|                           auto|\n",
      "|                         manual|\n",
      "|                           auto|\n",
      "|                         manual|\n",
      "|                           auto|\n",
      "|                           auto|\n",
      "|                           auto|\n",
      "|                           auto|\n",
      "|                           auto|\n",
      "+-------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.select(F.regexp_extract('trans', r'(\\w+)', 1)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3510d5ab",
   "metadata": {},
   "source": [
    "## 3. Load the tips dataset as a spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de585604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf = spark.createDataFrame(data('tips'))\n",
    "sdf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f09315",
   "metadata": {},
   "source": [
    "#### 3a. What percentage of observations are smokers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc6a527f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------+\n",
      "|avg(CASE WHEN (smoker = Yes) THEN 1 ELSE 0 END)|\n",
      "+-----------------------------------------------+\n",
      "|                            0.38114754098360654|\n",
      "+-----------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smoker_num = F.when(sdf.smoker == 'Yes', 1).otherwise(0)\n",
    "sdf.select(F.mean(smoker_num)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca2da15",
   "metadata": {},
   "source": [
    "#### 3b. Create a column that contains the tip percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28677285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "| (tip / total_bill)|\n",
      "+-------------------+\n",
      "|0.05944673337257211|\n",
      "|0.16054158607350097|\n",
      "|0.16658733936220846|\n",
      "+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tip_pct = sdf.tip / sdf.total_bill\n",
    "sdf.select(tip_pct).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1972ea",
   "metadata": {},
   "source": [
    "#### 3c. Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4221bbb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve 'sex' given input columns: [date, month, precipitation, temp_max, temp_min, weather, wind, year];\n'Aggregate ['sex, 'smoker], ['sex, 'smoker, avg((tip#95 / total_bill#94)) AS avg((tip / total_bill))#536]\n+- Project [date#189, precipitation#190, temp_max#226, temp_min#233, wind#193, weather#194, month#265, substring(date#189, 1, 4) AS year#370]\n   +- Project [date#189, precipitation#190, temp_max#226, temp_min#233, wind#193, weather#194, substring(date#189, 6, 2) AS month#265]\n      +- Project [date#189, precipitation#190, temp_max#226, ((temp_min#192 * 1.8) + cast(32 as double)) AS temp_min#233, wind#193, weather#194]\n         +- Project [date#189, precipitation#190, ((temp_max#191 * 1.8) + cast(32 as double)) AS temp_max#226, temp_min#192, wind#193, weather#194]\n            +- LogicalRDD [date#189, precipitation#190, temp_max#191, temp_min#192, wind#193, weather#194], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zb/3lg9b5xn3831bhkh23bd5bs00000gn/T/ipykernel_63996/1417692426.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sex'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'smoker'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtip_pct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pyspark/sql/group.py\u001b[0m in \u001b[0;36magg\u001b[0;34m(self, *exprs)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;31m# Columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexprs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"all exprs should be Column\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             jdf = self._jgd.agg(exprs[0]._jc,\n\u001b[0m\u001b[1;32m    119\u001b[0m                                 _to_seq(self.sql_ctx._sc, [c._jc for c in exprs[1:]]))\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve 'sex' given input columns: [date, month, precipitation, temp_max, temp_min, weather, wind, year];\n'Aggregate ['sex, 'smoker], ['sex, 'smoker, avg((tip#95 / total_bill#94)) AS avg((tip / total_bill))#536]\n+- Project [date#189, precipitation#190, temp_max#226, temp_min#233, wind#193, weather#194, month#265, substring(date#189, 1, 4) AS year#370]\n   +- Project [date#189, precipitation#190, temp_max#226, temp_min#233, wind#193, weather#194, substring(date#189, 6, 2) AS month#265]\n      +- Project [date#189, precipitation#190, temp_max#226, ((temp_min#192 * 1.8) + cast(32 as double)) AS temp_min#233, wind#193, weather#194]\n         +- Project [date#189, precipitation#190, ((temp_max#191 * 1.8) + cast(32 as double)) AS temp_max#226, temp_min#192, wind#193, weather#194]\n            +- LogicalRDD [date#189, precipitation#190, temp_max#191, temp_min#192, wind#193, weather#194], false\n"
     ]
    }
   ],
   "source": [
    "sdf.groupby('sex', 'smoker').agg(F.mean(tip_pct)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8286cb2",
   "metadata": {},
   "source": [
    "## 4. Use the seattle weather dataset referenced in the lesson to answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26048a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "|2012-01-05|          1.3|     8.9|     2.8| 6.1|   rain|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vega_datasets import data\n",
    "weather = data.seattle_weather().assign(date=lambda df: df.date.astype(str))\n",
    "sdf = spark.createDataFrame(weather)\n",
    "sdf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9929f605",
   "metadata": {},
   "source": [
    "#### 4a. Convert the temperatures to fahrenheit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38c0a24",
   "metadata": {},
   "source": [
    "(0°C × 9/5) + 32 = 32°F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "009f8ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+------------------+--------+----+-------+\n",
      "|      date|precipitation|          temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+------------------+--------+----+-------+\n",
      "|2012-01-01|          0.0|55.040000000000006|    41.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|             51.08|   37.04| 4.5|   rain|\n",
      "|2012-01-03|          0.8|             53.06|   44.96| 2.3|   rain|\n",
      "|2012-01-04|         20.3|             53.96|   42.08| 4.7|   rain|\n",
      "|2012-01-05|          1.3|48.019999999999996|   37.04| 6.1|   rain|\n",
      "+----------+-------------+------------------+--------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf = sdf.withColumn('temp_max', sdf.temp_max * (9/5) + 32)\n",
    "sdf = sdf.withColumn('temp_min', sdf.temp_min * (9/5) + 32)\n",
    "sdf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2119394",
   "metadata": {},
   "source": [
    "#### 4b. Which month has the most rain, on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fe3eeb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sdf = sdf.withColumn('month', sdf.date.substr(6, 2))\n",
    "rainy_days = sdf.filter((sdf.weather == 'rain') | (sdf.weather == 'drizzle'))\n",
    "rain_by_month = rainy_days.groupby('month').agg(F.mean('precipitation'))\n",
    "rain_by_month = rain_by_month.withColumnRenamed('avg(precipitation)', 'avg_rain')\n",
    "rain_by_month.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0029d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rain = rain_by_month.select(F.max('avg_rain')).head()[0]\n",
    "rain_by_month.filter(rain_by_month.avg_rain == max_rain).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b06a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_by_month.filter(rain_by_month.avg_rain == max_rain).select('month').head()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84040f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|month|avg_rain|\n",
      "+-----+--------+\n",
      "|   10|  8.0625|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rain_by_month.createOrReplaceTempView('rain_by_month')\n",
    "spark.sql('''SELECT month, avg_rain\n",
    "               FROM rain_by_month\n",
    "               WHERE avg_rain = (SELECT MAX(avg_rain)\n",
    "                                   FROM rain_by_month)''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a14728f",
   "metadata": {},
   "source": [
    "#### 4c. Which year was the windiest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ca48e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = sdf.withColumn('year', sdf.date.substr(1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9d74248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|year|          avg_wind|\n",
      "+----+------------------+\n",
      "|2012| 3.400819672131148|\n",
      "|2013|3.0158904109589058|\n",
      "|2014| 3.387671232876714|\n",
      "|2015| 3.159726027397261|\n",
      "+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wind_by_year = sdf.groupby('year').agg(F.mean('wind'))\n",
    "wind_by_year = wind_by_year.withColumnRenamed('avg(wind)', 'avg_wind')\n",
    "wind_by_year.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40b4ea41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+\n",
      "|year|         avg_wind|\n",
      "+----+-----------------+\n",
      "|2012|3.400819672131148|\n",
      "+----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_wind = wind_by_year.select(F.max('avg_wind')).head()[0]\n",
    "wind_by_year.filter(wind_by_year.avg_wind == max_wind).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbba2f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2012'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wind_by_year.filter(wind_by_year.avg_wind == max_wind).select('year').head()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ebb492",
   "metadata": {},
   "source": [
    "#### 4d. What is the most frequent type of weather in January?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87d14446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|weather|n_days|\n",
      "+-------+------+\n",
      "|drizzle|    10|\n",
      "|   rain|    35|\n",
      "|    sun|    33|\n",
      "|   snow|     8|\n",
      "|    fog|    38|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jan = sdf.filter(sdf.month == '01').groupby('weather').count()\n",
    "jan = jan.withColumnRenamed('count', 'n_days')\n",
    "jan.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d247f5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|weather|n_days|\n",
      "+-------+------+\n",
      "|    fog|    38|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_days = jan.select(F.max('n_days')).head()[0]\n",
    "jan.filter(jan.n_days == max_days).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9eac2882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fog'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jan.filter(jan.n_days == max_days).select('weather').head()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fee3299",
   "metadata": {},
   "source": [
    "#### 4e. What is the average high and low temperature on sunny days in July in 2013 and 2014?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa91e4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|    avg(temp_max)|\n",
      "+-----------------+\n",
      "|65.37874999999998|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sun_13_14 = sdf.filter(((sdf.year == 2013) | (sdf.year == 2014)) & (sdf.weather == 'sun'))\n",
    "sun_13_14.select(F.mean('temp_max')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0d88689f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|    avg(temp_min)|\n",
      "+-----------------+\n",
      "|48.28913461538461|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sun_13_14.select(F.mean('temp_min')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6e7000",
   "metadata": {},
   "source": [
    "#### 4f. What percentage of days were rainy in q3 of 2015?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bfa9bd78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sdf = sdf.withColumn('quarter', F.when(sdf.month.isin(['01', '02', '03']), 1)\n",
    "                                 .when(sdf.month.isin(['04', '05', '06']), 2)\n",
    "                                 .when(sdf.month.isin(['07', '08', '09']), 3)\n",
    "                                 .otherwise(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "70209b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|          avg(rainy)|\n",
      "+--------------------+\n",
      "|0.021739130434782608|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q3_15 = sdf.filter((sdf.quarter == 3) & (sdf.year == '2015'))\n",
    "q3_15 = q3_15.withColumn('rainy', F.when(q3_15.weather == 'rain', 1)\n",
    "                                   .otherwise(0))\n",
    "q3_15.select(F.mean(q3_15.rainy)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503543ba",
   "metadata": {},
   "source": [
    "#### 4g. For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4230c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.withColumn('had_precip', F.when(sdf.precipitation > 0, 1)\n",
    "                              .otherwise(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
